{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Constructing a Text Generation Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c03_nlp_constructing_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GbGfr_oLCat"
      },
      "source": [
        "Using most of the techniques you've already learned, it's now possible to generate new text by predicting the next word that follows a given seed word. To practice this method, we'll use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "095c8dc1-7be0-4786-9af1-79d033517c7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 06:24:46--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.118.102, 172.253.118.138, 172.253.118.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.118.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nssmdr3t86cc2uc57q6sgjh5dubpd354/1680243825000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=ef11fe71-dd7b-48a0-b648-8f3744e362dd [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-31 06:24:48--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/nssmdr3t86cc2uc57q6sgjh5dubpd354/1680243825000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=ef11fe71-dd7b-48a0-b648-8f3744e362dd\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.200.132, 2404:6800:4003:c00::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.200.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M   200MB/s    in 0.3s    \n",
            "\n",
            "2023-03-31 06:24:49 (200 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu1BTzMIS1oy"
      },
      "source": [
        "## **First 10 Songs**\n",
        "\n",
        "Let's first look at just 10 songs from the dataset, and see how things perform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmb9rGaAUDO-"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "Let's perform some basic preprocessing to get rid of punctuation and make everything lowercase. We'll then split the lyrics up by line and tokenize the lyrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2AVAvyF_Vuh5"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "apcEXp7WhVBs",
        "outputId": "f239780f-dc7f-4bd4-ef9e-9e9c30ce2487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-3-fbdddccf8583>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-3-fbdddccf8583>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.lower()\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9x68iN_X6FK"
      },
      "source": [
        "### Create Sequences and Labels\n",
        "\n",
        "After preprocessing, we next need to create sequences and labels. Creating the sequences themselves is similar to before with `texts_to_sequences`, but also including the use of [N-Grams](https://towardsdatascience.com/introduction-to-language-models-n-gram-e323081503d9); creating the labels will now utilize those sequences as well as utilize one-hot encoding over all potential output words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmlTsUqfikVO"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zsmu3aEId49i",
        "outputId": "5c9090dd-f2db-4248-fdb1-327ca27ddb63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1TAJMlmfO8r"
      },
      "source": [
        "### Train a Text Generation Model\n",
        "\n",
        "Building an RNN to train our text generation model will be very similar to the sentiment models you've built previously. The only real change necessary is to make sure to use Categorical instead of Binary Cross Entropy as the loss function - we could use Binary before since the sentiment was only 0 or 1, but now there are hundreds of categories.\n",
        "\n",
        "From there, we should also consider using *more* epochs than before, as text generation can take a little longer to converge than sentiment analysis, *and* we aren't working with all that much data yet. I'll set it at 200 epochs here since we're only use part of the dataset, and training will tail off quite a bit over that many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G1YXuxIqfygN",
        "outputId": "40c576d5-3f25-43e0-8787-1b1bf0ca69e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 21s 109ms/step - loss: 6.0203 - accuracy: 0.0328\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 3s 45ms/step - loss: 5.4421 - accuracy: 0.0399\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 1s 20ms/step - loss: 5.3628 - accuracy: 0.0399\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 2s 36ms/step - loss: 5.3068 - accuracy: 0.0409\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 1s 15ms/step - loss: 5.2404 - accuracy: 0.0419\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 5.1659 - accuracy: 0.0424\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 5.0974 - accuracy: 0.0429\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 5.0213 - accuracy: 0.0651\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 4.9443 - accuracy: 0.0686\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.8478 - accuracy: 0.0792\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.7519 - accuracy: 0.0994\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.6462 - accuracy: 0.1054\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.5290 - accuracy: 0.1297\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.4179 - accuracy: 0.1433\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.3036 - accuracy: 0.1473\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 4.1933 - accuracy: 0.1726\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0885 - accuracy: 0.1796\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.9778 - accuracy: 0.1831\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.8720 - accuracy: 0.2013\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 3.7723 - accuracy: 0.2190\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6771 - accuracy: 0.2437\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.5835 - accuracy: 0.2563\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4986 - accuracy: 0.2745\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.4166 - accuracy: 0.3058\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.3295 - accuracy: 0.3199\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.2597 - accuracy: 0.3320\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 3.1793 - accuracy: 0.3572\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 3.0990 - accuracy: 0.3729\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0234 - accuracy: 0.3880\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9499 - accuracy: 0.4062\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.8836 - accuracy: 0.4208\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8123 - accuracy: 0.4329\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7522 - accuracy: 0.4435\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7083 - accuracy: 0.4601\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6313 - accuracy: 0.4768\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5969 - accuracy: 0.4808\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5300 - accuracy: 0.4889\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4658 - accuracy: 0.5030\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4250 - accuracy: 0.5116\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3651 - accuracy: 0.5202\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 2.3011 - accuracy: 0.5323\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.2778 - accuracy: 0.5383\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2161 - accuracy: 0.5540\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1625 - accuracy: 0.5631\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1116 - accuracy: 0.5772\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0874 - accuracy: 0.5772\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0560 - accuracy: 0.5883\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 2.0006 - accuracy: 0.5984\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9534 - accuracy: 0.6075\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.8995 - accuracy: 0.6196\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.8953 - accuracy: 0.6160\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 1s 16ms/step - loss: 1.8353 - accuracy: 0.6276\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 1s 12ms/step - loss: 1.8025 - accuracy: 0.6357\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7528 - accuracy: 0.6504\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 1s 11ms/step - loss: 1.7191 - accuracy: 0.6574\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6961 - accuracy: 0.6609\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6660 - accuracy: 0.6584\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6255 - accuracy: 0.6756\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.5881 - accuracy: 0.6781\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5628 - accuracy: 0.6857\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5405 - accuracy: 0.6953\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5310 - accuracy: 0.6892\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4920 - accuracy: 0.7008\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4593 - accuracy: 0.6988\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4305 - accuracy: 0.7104\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3956 - accuracy: 0.7220\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3775 - accuracy: 0.7190\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3452 - accuracy: 0.7306\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3165 - accuracy: 0.7472\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3004 - accuracy: 0.7402\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2711 - accuracy: 0.7543\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2443 - accuracy: 0.7588\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2120 - accuracy: 0.7659\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 1.1979 - accuracy: 0.7629\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.1777 - accuracy: 0.7664\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 1.1601 - accuracy: 0.7790\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 1.1319 - accuracy: 0.7891\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 1s 8ms/step - loss: 1.1130 - accuracy: 0.7911\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0892 - accuracy: 0.7957\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0705 - accuracy: 0.8002\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0540 - accuracy: 0.7967\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0388 - accuracy: 0.8058\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0227 - accuracy: 0.8058\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0039 - accuracy: 0.8098\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 1s 13ms/step - loss: 0.9873 - accuracy: 0.8148\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9792 - accuracy: 0.8133\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9738 - accuracy: 0.8143\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9573 - accuracy: 0.8179\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9426 - accuracy: 0.8214\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9305 - accuracy: 0.8184\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9277 - accuracy: 0.8174\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9002 - accuracy: 0.8234\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8764 - accuracy: 0.8254\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8629 - accuracy: 0.8320\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8437 - accuracy: 0.8370\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8212 - accuracy: 0.8406\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8087 - accuracy: 0.8416\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7963 - accuracy: 0.8446\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8033 - accuracy: 0.8426\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.8028 - accuracy: 0.8406\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.8128 - accuracy: 0.8300\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.7732 - accuracy: 0.8421\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.7522 - accuracy: 0.8522\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7362 - accuracy: 0.8512\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8257 - accuracy: 0.8244\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7871 - accuracy: 0.8335\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7364 - accuracy: 0.8481\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7143 - accuracy: 0.8491\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7002 - accuracy: 0.8537\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6848 - accuracy: 0.8587\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6706 - accuracy: 0.8597\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6568 - accuracy: 0.8648\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6479 - accuracy: 0.8648\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6390 - accuracy: 0.8698\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6369 - accuracy: 0.8648\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6318 - accuracy: 0.8628\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6210 - accuracy: 0.8688\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6105 - accuracy: 0.8734\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5993 - accuracy: 0.8718\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5907 - accuracy: 0.8703\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5896 - accuracy: 0.8729\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5820 - accuracy: 0.8759\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5721 - accuracy: 0.8703\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5724 - accuracy: 0.8718\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5727 - accuracy: 0.8734\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5749 - accuracy: 0.8734\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5624 - accuracy: 0.8764\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.5568 - accuracy: 0.8784\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5420 - accuracy: 0.8744\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.5359 - accuracy: 0.8809\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5303 - accuracy: 0.8794\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.8814\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5139 - accuracy: 0.8794\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.5155 - accuracy: 0.8809\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5020 - accuracy: 0.8840\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 1s 7ms/step - loss: 0.4914 - accuracy: 0.8850\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.8824\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.4802 - accuracy: 0.8890\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4722 - accuracy: 0.8850\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4687 - accuracy: 0.8900\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4630 - accuracy: 0.8905\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4754 - accuracy: 0.8835\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5008 - accuracy: 0.8824\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4823 - accuracy: 0.8824\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.8875\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4587 - accuracy: 0.8860\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.8850\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5059 - accuracy: 0.8804\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4901 - accuracy: 0.8769\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4702 - accuracy: 0.8840\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.8840\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.8870\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4472 - accuracy: 0.8935\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 1s 14ms/step - loss: 0.4268 - accuracy: 0.8951\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.4157 - accuracy: 0.8961\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4100 - accuracy: 0.8935\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4065 - accuracy: 0.8946\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4056 - accuracy: 0.8961\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3992 - accuracy: 0.8956\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4004 - accuracy: 0.8940\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3913 - accuracy: 0.8996\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3864 - accuracy: 0.8981\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.3813 - accuracy: 0.9011\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3793 - accuracy: 0.8986\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3748 - accuracy: 0.8991\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3727 - accuracy: 0.9031\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.9006\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.9016\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3652 - accuracy: 0.9006\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3635 - accuracy: 0.9016\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3747 - accuracy: 0.9016\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.9031\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3916 - accuracy: 0.8946\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3924 - accuracy: 0.8900\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3977 - accuracy: 0.8890\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3905 - accuracy: 0.8925\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3739 - accuracy: 0.8971\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.9041\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.3502 - accuracy: 0.9036\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.3447 - accuracy: 0.9051\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 1s 10ms/step - loss: 0.3394 - accuracy: 0.9057\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 1s 9ms/step - loss: 0.3369 - accuracy: 0.9046\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3355 - accuracy: 0.9067\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.9072\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3305 - accuracy: 0.9041\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.9077\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3272 - accuracy: 0.9041\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3239 - accuracy: 0.9082\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3204 - accuracy: 0.9087\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3214 - accuracy: 0.9051\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3274 - accuracy: 0.9041\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3177 - accuracy: 0.9062\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 8ms/step - loss: 0.3150 - accuracy: 0.9062\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3109 - accuracy: 0.9077\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3079 - accuracy: 0.9072\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3074 - accuracy: 0.9082\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3035 - accuracy: 0.9067\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3037 - accuracy: 0.9072\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3038 - accuracy: 0.9082\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.3044 - accuracy: 0.9062\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXVFpoREhV6Y"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aeSNfS7uhch0",
        "outputId": "30538f67-9008-464c-8def-65f7aa00f80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rAgRpxYhjpB"
      },
      "source": [
        "### Generate new lyrics!\n",
        "\n",
        "It's finally time to generate some new lyrics from the trained model, and see what we get. To do so, we'll provide some \"seed text\", or an input sequence for the model to start with. We'll also decide just how long of an output sequence we want - this could essentially be infinite, as the input plus the previous output will be continuously fed in for a new output word (at least up to our max sequence length)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DC7zfcgviDTp",
        "outputId": "a5e6e27d-a845-4411-ee5e-f9bd9a785137",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 736ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "im feeling chills me the truth leaving and handle quiet of us would better throwing would car shame joe enchained showing shame chiquitita had chiquitita used wanna didnt weave weave have chiquitita have be chiquitita know deny as for good as dreams you would weave weave weave weave weave wanna car throwing dont car wanna car car dont car wanna car car dont morning wanna morning know am hate again and what you didnt do what to blue eyes filled feet cassandra here i am again make me strong break again and stay sailing sailing friend talking again and once what and im\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c03_nlp_constructing_text_generation_model.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}