{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "c4c9437d-f1a5-423f-e96e-d62795093269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 06:03:02--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 172.253.117.102, 172.253.117.113, 172.253.117.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|172.253.117.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dqf3ok5ec61i388sr22en8hfpeiimrbd/1680242550000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=06d57990-c5a9-4ae2-b6a1-47c50dbc5edf [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-31 06:03:04--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/dqf3ok5ec61i388sr22en8hfpeiimrbd/1680242550000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=06d57990-c5a9-4ae2-b6a1-47c50dbc5edf\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 142.250.107.132, 2607:f8b0:400e:c0d::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|142.250.107.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M   166MB/s    in 0.4s    \n",
            "\n",
            "2023-03-31 06:03:05 (166 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kIGedF3XjHj4",
        "outputId": "28dabbac-b5b6-44f4-8f78-a92cab08def0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "outputId": "8248d5d2-5c3f-4daf-8549-b04c1e1fad5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 32s 14ms/step - loss: 5.9820 - accuracy: 0.0462\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 5.6836 - accuracy: 0.0502\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.4784 - accuracy: 0.0693\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 5.3012 - accuracy: 0.0947\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 18s 12ms/step - loss: 5.1152 - accuracy: 0.1192\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.9177 - accuracy: 0.1373\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.7413 - accuracy: 0.1558\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 4.5910 - accuracy: 0.1705\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.4607 - accuracy: 0.1833\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.3458 - accuracy: 0.1974\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.2397 - accuracy: 0.2108\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.1447 - accuracy: 0.2208\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.0590 - accuracy: 0.2318\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.9768 - accuracy: 0.2420\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.9042 - accuracy: 0.2498\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.8339 - accuracy: 0.2602\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.7731 - accuracy: 0.2688\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7119 - accuracy: 0.2784\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6560 - accuracy: 0.2854\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6049 - accuracy: 0.2913\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.5547 - accuracy: 0.2989\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.5088 - accuracy: 0.3046\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.4656 - accuracy: 0.3111\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.4211 - accuracy: 0.3172\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.3844 - accuracy: 0.3217\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3455 - accuracy: 0.3282\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3146 - accuracy: 0.3324\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2799 - accuracy: 0.3379\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2423 - accuracy: 0.3428\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.2144 - accuracy: 0.3495\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1886 - accuracy: 0.3511\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1530 - accuracy: 0.3572\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1294 - accuracy: 0.3620\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1027 - accuracy: 0.3639\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0756 - accuracy: 0.3683\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0472 - accuracy: 0.3736\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0234 - accuracy: 0.3778\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 3.0056 - accuracy: 0.3801\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9830 - accuracy: 0.3836\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9583 - accuracy: 0.3890\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.9332 - accuracy: 0.3920\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9161 - accuracy: 0.3955\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9034 - accuracy: 0.3987\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8759 - accuracy: 0.4038\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.8671 - accuracy: 0.4040\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8434 - accuracy: 0.4058\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.8264 - accuracy: 0.4109\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8197 - accuracy: 0.4130\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7956 - accuracy: 0.4170\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7768 - accuracy: 0.4197\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7637 - accuracy: 0.4215\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7414 - accuracy: 0.4266\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7330 - accuracy: 0.4269\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7151 - accuracy: 0.4295\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7000 - accuracy: 0.4319\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6836 - accuracy: 0.4358\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6728 - accuracy: 0.4387\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6585 - accuracy: 0.4400\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 2.6407 - accuracy: 0.4432\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6327 - accuracy: 0.4449\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6191 - accuracy: 0.4449\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6028 - accuracy: 0.4492\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6067 - accuracy: 0.4485\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5777 - accuracy: 0.4559\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5690 - accuracy: 0.4554\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5691 - accuracy: 0.4555\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5488 - accuracy: 0.4586\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5367 - accuracy: 0.4611\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5217 - accuracy: 0.4647\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5239 - accuracy: 0.4638\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5064 - accuracy: 0.4662\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4898 - accuracy: 0.4709\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4898 - accuracy: 0.4692\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4786 - accuracy: 0.4715\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4636 - accuracy: 0.4748\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4508 - accuracy: 0.4768\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4464 - accuracy: 0.4778\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4485 - accuracy: 0.4759\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4249 - accuracy: 0.4812\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4154 - accuracy: 0.4853\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4066 - accuracy: 0.4838\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4129 - accuracy: 0.4830\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4035 - accuracy: 0.4861\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3790 - accuracy: 0.4898\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3751 - accuracy: 0.4907\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3984 - accuracy: 0.4855\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3773 - accuracy: 0.4899\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3655 - accuracy: 0.4932\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 2.3474 - accuracy: 0.4958\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3475 - accuracy: 0.4948\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3432 - accuracy: 0.4946\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3234 - accuracy: 0.5014\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3269 - accuracy: 0.4985\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3169 - accuracy: 0.4995\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3050 - accuracy: 0.5015\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3002 - accuracy: 0.5017\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.2965 - accuracy: 0.5048\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 2.2813 - accuracy: 0.5066\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.2752 - accuracy: 0.5068\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.2714 - accuracy: 0.5090\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rOqmmarvlSLh",
        "outputId": "9e65cd14-b876-4bc4-a43b-ff8e01e3d7e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHHElEQVR4nO3deVxU5eIG8GdmYIZ9F5B9c0PFBQRxLaUwzbKsvGZKVJa5ZHG7t2zRlltY+evazdLqZt1bpma3vJapKS6Z4YaCG+Iu67DIMqwzMPP+/qCmuC6xDJyZ4fl+Pnw+zpkzw8NbMo/nvOc9MiGEABEREZGVkEsdgIiIiMiUWG6IiIjIqrDcEBERkVVhuSEiIiKrwnJDREREVoXlhoiIiKwKyw0RERFZFRupA3Q1g8GAwsJCODs7QyaTSR2HiIiIWkEIgerqavj5+UEuv/GxmW5XbgoLCxEYGCh1DCIiImqHvLw8BAQE3HCfbldunJ2dATQPjouLi8RpiIiIqDU0Gg0CAwONn+M30u3Kza+nolxcXFhuiIiILExrppRwQjERERFZFZYbIiIisiosN0RERGRVWG6IiIjIqrDcEBERkVVhuSEiIiKrwnJDREREVoXlhoiIiKwKyw0RERFZFZYbIiIisiosN0RERGRVWG6IiIjIqrDcEBERkckUVtbjXEmNpBm63V3BiYiIyLTKa3X4/ngRNmUV4uDFctwS6YOPZsVIloflhoiIiP7QlRotDl4sR1V9I+ob9ahv1KOh0YATBVX48UwpmgzCuG+9Tg+DQUAul0mSleWGiIiIriKEwMlCDXaeLsHO0yXIyq+EENffv7+fC+4Y5IfbB/nB382+64JeA8sNERERGTXqDfjmaAFW7j6Pi2W1LZ7r6+uMAHd7qGwVsLdVwM5WDh9nO9w20BcR3s4SJb6aWZSb9957D2+99RbUajUGDRqEd999F7Gxsdfc99NPP0VycnKLbSqVCg0NDV0RlYiIyCo1NOqxISMfq3afR0FlPQDAQanAyAgvjOvrjZv7eMPX1U7ilK0jeblZv349UlJSsGrVKsTFxWH58uVITExETk4OvL29r/kaFxcX5OTkGB/LZNKc0yMiIpLSycIq7M4pxR2D/BDo4fCH+zfqDdh/4Qp2nCpGQWU9tE0G41dBRR3KanQAAC8nFR4bE4b744LgqJK8KrSZ5InffvttzJ4923g0ZtWqVdi8eTNWr16NZ5999pqvkclk8PX1bdX7a7VaaLVa42ONRtPx0ERERBI7UVCFP324HzXaJry9/QwmDeyJR8eEYYC/q3EfIQRKqrU4mluBbSeLkZZdDE1D03Xf08/VDnNuCsd9MYGws1V0xY/RKSQtNzqdDhkZGVi0aJFxm1wuR0JCAtLT06/7upqaGgQHB8NgMGDo0KF4/fXX0b9//2vum5qaipdfftnk2YmIiKRyobQGSasPokbbBC8nFcpqtNiUVYhNWYUYGeGJIA9HnC2uxtmSGlTVN7Z4rZeTErdE+iAqwA12tnKobBRQKuRwVNkgOtgdShvLXwJP0nJTVlYGvV4PHx+fFtt9fHxw+vTpa76mT58+WL16NaKiolBVVYVly5ZhxIgROHnyJAICAq7af9GiRUhJSTE+1mg0CAwMNO0PQkRE1EWKquox8+ODuFKrwwB/F6ydPRyXr9Tho70X8N2xIuw7dwX7cMW4v1wGhHo54qY+3pgwwBdDg9yhkOgS7a4i+WmptoqPj0d8fLzx8YgRI9CvXz988MEHePXVV6/aX6VSQaVSdWVEIiKiNskrr8OO7GI429ki1MsR4T0c4eagvGq/ilodZn18EAWV9Qj1csSnybFwtrPFAH9XvPOnIfhLYh98eTgfeoMBvX2c0cvbGWE9HC36FFN7SFpuvLy8oFAoUFxc3GJ7cXFxq+fU2NraYsiQITh37lxnRCQiIuoUeoPAj2dK8dn+y9iVU3LVGjIejkr4u9nDQamAvVIBB6UCZ4trcLakBr4udvjs4Vh4ObX8x3uAuwNSbundhT+FeZK03CiVSkRHRyMtLQ1TpkwBABgMBqSlpWH+/Pmteg+9Xo/jx49j4sSJnZiUiIjINBoa9fh8/2V8+vMl5FfUG7fHhXpAIZfhQmkt1JoGlNfqUF6ru+r1bg62+OzhWAS4//HVUd2V5KelUlJSkJSUhJiYGMTGxmL58uWora01Xj01a9Ys+Pv7IzU1FQDwyiuvYPjw4YiIiEBlZSXeeustXL58GY888oiUPwYREdENNeoN+PJwHv6RdhbFmuareF3tbXFPdABmxAUhrIeTcd9abRMultWiWNOA+kY96nR6NDTqoWsy4NZIXwR5stjciOTlZtq0aSgtLcXixYuhVqsxePBgbN261TjJODc3F3L5bzO3KyoqMHv2bKjVari7uyM6Oho///wzIiMjpfoRiIiom6iqa8RptQaXrtTiQlktLpXVQtdkwNybIzAsxOOarzEYBL49Voi3t5/B5St1AAB/N3ssGBeBKUP8rzkfxlFlgwH+ri0u66bWkwlxoztFWB+NRgNXV1dUVVXBxcVF6jhERGQB6nV6rNx9Dqt+vABdk+Gq520VMrxy5wBMjw1qsb2gsh5Pf5mF9AvNVy95OSkx/+YITI8Lgsqme03y7ai2fH5LfuSGiIjIXAkhsOWEGq9tzjbeksDfzR5hPRwR6uWIEE9HHL5cju+Pq7Ho6+M4XaTBC7dHwkYuw8bMAizeeBLV2ibY2yowf1wEkkeGwEHJj97OxhEmIiK6hpOFVXhtczZ+Pt981MXfzR4vTOqHCQN8W9z2J3lkCN7bdQ7LfjiDf6VfxtmSGrg7KLH5eBEAYEiQG/5+32CEeDlK8nN0Ryw3RERktYQQ+OZoAVbvuwh3ByXiQj0QG+qJqADX6679kpVXiXd3nsOO7OZlSpQ2cswZG47Hx4bDXnn1a2QyGeaP64VePs5IWZ9pLEM2chmeTOiFOWPDYaOw/FV/LQnn3BARkVXKr6jDc9+cwI9nSq96TmkjR38/FwR5OCDA3R4B7g5wtbfF+kN52PPL/jIZcHuUH/6a2KdVN6UEgBx1NeZ/cQS2CjnemBqFgQGcEGwqbfn8ZrkhIiKrojcIfJZ+CW9uy0GdTg+ljRzzb46Aq70tDl4sx4GL5Sir0V739Qq5DHcO9sO8myMQ/rvLs1tLCNHitBWZBicUExFRt1Req8Pjn2fgwMVyAEBsiAdSpw40lpSkESEQQuBCWS2yizQoqKhHfkU98ivqoNZoMTjQFXPGhiPYs/3zY1hspMdyQ0REVuF8aQ0e+vQQLl+pg6NSgUUT++H+2CDI/+cmkTKZDOE9nNp1VIYsA8sNERGZvaq6Rpwvq8HF0lo429lgZIQXHFW/fYSln7+COZ9noKq+EQHu9vjkwWHo5eMsYWKSEssNERGZFSEEThVp8MPJYqSfv4LzpTW48j/3WFIq5Bge7omEft6QAXjlu1No1AsMCXLDR7NirrqhJHUvLDdERGQWMi5XYPOxIvxwSt3ihpK/8nWxQ4iXA4qqGnD5Sh1+PFPa4kqoSVE98X/3DrruJd7UfbDcEBGRpI7nV+HNbaex92yZcZudrRxjevVAQj8fRPq5INTL0XgaSgiB86U12JFdgrTsYmTlV+HR0WFIuaX3VfNrqHtiuSEiIklcKK3B/20/g83HmlfytVXIcHuUHyYM8MWYXj2uuWAe0DwhOMLbGRHezpgzNrwrI5OFYLkhIiKTOq3W4Fh+FYYGuSO8h2OLS6Mb9QbsPVuK/xwpwNYTaugNAjIZMGWwP55K6I0gz9Ytlkd0Iyw3RERkEgaDwEd7L+DNbTnQG5rXh/V3s8eY3l6IC/XEsfwqbMoqQFnNb5ODx/f1xtOJfdCvJxdVJdPhCsVERNRhlXU6/PnLLKSdLgEA9PFxxsWyWuj0hqv29XRU4o7Bfpg6NAAD/Hl7AmodrlBMRERd5mhuBeZ/cRQFlfVQ2sixZHIk7o8NQkOjAfsvXsGPZ0px+FIFgjwccPdQf4zp3QO2vJEkdSKWGyIiarMmvQF7z5bhy8N52H6qGE0GgRBPB6y4f6jxaIy9UoGb+3jj5j7eEqel7oblhoiIrlKrbcKqPefxVUY+XOxsEeLlgBAvR4R6OiKvog5fZeSjWPPbzScnRfXE0rsHwtnOVsLURM1YboiIyMhgENiYWYA3tp42lpeiqgbkFFdfta+7gy3uGhKA+4YFoK8v5zCS+WC5ISIiCCFw+HIFXtucjcy8SgBAkIcD/pLYB052NrhUVotLZbW4eKUOdjZyTBnij/H9vKGy4WrAZH5YboiIurHqhkZszCzEFwdykV2kAQA4KhWYNy4CD40M/e1WBn0kDEnURiw3RETd0NniaqzedxH/zSxEnU4PAFDZyHH30ObF9Lxd7CROSNR+LDdERN3IiYIqrNh5DltPqo3bwns44v64YEwd6g83B6WE6YhMg+WGiMiCaZv0+Ofei2ho1MPTUQkvZxU8HVVwsbdBk15ApzdA12RAdUMj1h7Mw57f3UU7sb8PHhoZithQjxa3SCCydCw3REQWSgiB574+gf8cyW/1a+Qy4I5Bfph7cwR6+zh3Yjoi6bDcEBFZqJV7zuM/R/IhlwH3RAeguqEJV2p0KKvVorqhCUqFHEobOZQKOWxtZIgKcMOjo8MQ4uUodXSiTsVyQ0RkgbaeKMKbW3MAAC/d0R+z4kOkDURkRnhzDyIiC3M8vwpPrs8EACTFB7PYEP0PHrkhIjJT50qq8dGPFwEAfm726OlmB09HJZ775jgaGg0Y07sHXrw9UuKUROaH5YaIyMzoDQKrf7qIt37Iga7JcM19enk7YcX9Q2DDu2sTXYXlhojIjFy+UounN2Th0KUKAMDY3j0wNMgdRVX1KKisR1FVA1Q2cqx6IBouvEkl0TWx3BARdbGKWh32nitDxqVy6PTCuL1Jb8B3x4pQ36iHo1KBF2+PxLRhgVyDhqiNWG6IiLrAabUGW0+osedMKbLyKmEQ1983LtQDy+4dhEAPh64LSGRFWG6IiDrRycIqvLPjLH44Vdxiex8fZ4yM8IKbQ8tTS8GeDpgc5Qe5nEdriNqL5YaIqBOcLKzCP9LOYtvJ5lIjkwHj+/ogoZ83xvbpgZ6u9hInJLJeLDdERB3U0KjHycIqZOVVISu/Esfyq3CxrBZAc6m5Y5AfFoyLQIQ3b3dA1BVYboiI2qmkugEf/3QRa/bnokbb1OI5mQyYHOWHJ8az1BB1NZYbIqI2yr1Shw9+PI8NGfnGdWi8nJQYHOiGqAA3DAp0Q5S/K9wdlRInJeqeWG6IiFqpsk6HN7bmYP2hXOPVTkOD3DD3pgiM6+vNScBEZoLlhojoDwgh8FVGPlK3nEZ5rQ5A8+J6j98UjrhQD65DQ2RmWG6IiG4gR12NFzYeN64Y3NvHCX+bMhCxoR4SJyOi62G5ISL6Hw2Nemw7qcaGw/nYd74MQgD2tgo8mdALD40KhS3v50Rk1lhuiIh+kZVXiXWH8vBdViGqf3f1U2J/Hyye3B/+blybhsgSsNwQUbdWr9Pj22OF+Hz/ZRzLrzJu93ezxz3RAbgnOoC3QSCyMCw3RNQtlFZrcSS3ArXaJtRom1Dd0ISiqnp8m1WEqvpGAIBSIcfEgb64b1gghod68uonIgvFckNEVm/X6RI8sfZoi1NNvxfgbo8Hhgfj3ugAeDqpujgdEZkayw0RWS0hBFbtuYA3t52GEECIpwMCPRzgbGcDJ5UNnO1sMTLCE2N7e0PBozREVoPlhoisUr1Oj2f+cwybsgoBANNjg/DyHf2htOGVTkTWjuWGiKyKpqERP58rw4pd53CiQAMbuQwv3dEfDwwPljoaEXURlhsisnjnSqrxw6li7M4pxZHLFWj65d4IHo5KvD9jKIaHeUqckIi6EssNEVkkg0Fgz9lSrP7pIvaeLWvxXJiXI8b26YFHRodxbRqibojlhogsirZJj68y8rH6p4s4X1oLAJDLmu/1NK6vN8b29kaQJ9elIerOWG6IyGKkn7+C5785jgtlzaXGSWWDacMC8eCIEC60R0RGLDdEZPYqanV4/ftsbMjIBwD0cFZhzthw3BcTAGc7W4nTEZG5YbkhIrNVp2vCt1mFeGNrDsprdQCAGXFB+OuEvnC1Z6khomtjuSEis1Kv02NXTgk2HytC2uliNDQaAAC9fZyQevdARAd7SJyQiMwdyw0RmQWDQeDdneewas951DfqjduDPR0wPTYID40M5QJ8RNQqLDdEJLnqhkY8tT4TO7JLADTf62lSVE9MjvJDfz8XyGS8NQIRtR7LDRFJ6nxpDR7992GcL62F0kaO16YMwD3RASw0RNRuLDdEJAkhBLafKsafv8xCtbYJvi52+GBmNAYFukkdjYgsHMsNEXWZep0eP58vQ9rpEuw+XYLCqgYAwLAQd7w/Ixo9nFUSJyQia2AW5ea9997DW2+9BbVajUGDBuHdd99FbGzsH75u3bp1mD59Ou68805s3Lix84MSUavkXqnD29tzoNY0oKHRgIZGPRoa9SiqaoC2yWDcz85Wjvtjg/HsbX05WZiITEbycrN+/XqkpKRg1apViIuLw/Lly5GYmIicnBx4e3tf93WXLl3C008/jdGjR3dhWiL6Iz+dLcO8L46gqr7xms/7u9ljXF9vjOvrjfhwT9jZKro4IRFZO5kQQkgZIC4uDsOGDcOKFSsAAAaDAYGBgViwYAGeffbZa75Gr9djzJgxeOihh7B3715UVla2+siNRqOBq6srqqqq4OLiYqofg6jbE0Lg458u4vXvs2EQwKBANzw0MgQOShvY2cphb6uAh6MSoV6OnCxMRG3Wls9vSY/c6HQ6ZGRkYNGiRcZtcrkcCQkJSE9Pv+7rXnnlFXh7e+Phhx/G3r17b/g9tFottFqt8bFGo+l4cCJqoaFRj0VfH8c3RwsAAPdGB+DVKQN4VIaIJCFpuSkrK4Ner4ePj0+L7T4+Pjh9+vQ1X/PTTz/h448/RmZmZqu+R2pqKl5++eWORiWiazAYBDYfL8LyHWdwvrQWCrkML07qh6QRITw6Q0SSkXzOTVtUV1dj5syZ+Oijj+Dl5dWq1yxatAgpKSnGxxqNBoGBgZ0VkahbMBgEtpxQ4520MzhTXAMA8HRU4t37h2BEeOv+bhIRdRZJy42XlxcUCgWKi4tbbC8uLoavr+9V+58/fx6XLl3C5MmTjdsMhuYrL2xsbJCTk4Pw8PAWr1GpVFCpeHkpkansyinBG1tO47S6GgDgYmeDR0aH4cGRIXDhHbqJyAxIWm6USiWio6ORlpaGKVOmAGguK2lpaZg/f/5V+/ft2xfHjx9vse2FF15AdXU13nnnHR6RIepEZ4ur8bfN2dhzphQA4KyywUOjQvHQqFDeoZuIzIrkp6VSUlKQlJSEmJgYxMbGYvny5aitrUVycjIAYNasWfD390dqairs7OwwYMCAFq93c3MDgKu2E5FplNfqsHzHGaw5kAu9QcBWIUPyyFDMuykCrg4sNURkfiQvN9OmTUNpaSkWL14MtVqNwYMHY+vWrcZJxrm5uZDLubgXUVdTVzVg9b6LWLP/Mmp1zXfpTuzvg0W39UOIl6PE6YiIrk/ydW66Gte5Ibqx86U1+HDPBXx9NB+N+uZfD5E9XfDC7f04WZiIJGMx69wQkfkQQuDt7WewYtc5/PpPntgQDzx+Uzhu6tODl3YTkcVguSEiaJv0+OtXx/DfzEIAwPi+3nj8pnDEhHhInIyIqO1Yboi6uaq6Rjz62WEcuFgOG7kMr989EPfF8MpDIrJcLDdE3VheeR0e/OQgzpfWwkllg5UPDMXoXj2kjkVE1CEsN0TdUJPegLWH8vD2DzmoqGuEr4sdPkkehn49OcmeiCwfyw1RNyKEwK6cErz+/WmcK2m+bUJkTxd8/GAMerraS5yOiMg0WG6IugGDQWD/xSt4f9d5/HSuDADg4ajEkwm9MD02CLYKriVFRNaD5YbIip1Wa/DN0QJsyixEUVUDAECpkCN5ZAjm3hzB2yYQkVViuSGyQkdyK7DkvydxvKDKuM3Zzga3R/lh7k3hCPRwkDAdEVHnYrkhsiINjXr8ffsZfLT3AgwCsFXIMK6vN+4a4o+b+njDzlYhdUQiok7HckNkJY7mVuDpDVk4X1oLALhriD9emNQPnk4qiZMREXUtlhsiC2cwCCxPO4sVO8/CIIAeziq8ftdA3BLpI3U0IiJJsNwQWbB6nR5/3pCJ74+rATQfrVkyORJuDkqJkxERSYflhshClWga8Mi/D+NYfhVsFTKk3h2Fe6IDpI5FRCQ5lhsiC3SysAqP/Oswiqoa4OZgiw8eiEZcmKfUsYiIzALLDZEFEULgm6MFeGHjCdTp9Ajr4YjVScMQ4uUodTQiIrPBckNkIarqG/HCxhP4NqsQADAqwgvv3T8Urg5ciI+I6PdYbogswP4LV5CyPhOFVQ1QyGV4KqEXHr8pAgq5TOpoRERmh+WGyEzV6/TYd64M206q8dWRfAgBBHs6YPm0wRgS5C51PCIis8VyQ2RGGhr12JCRjx2nipF+4Qp0TQbjc/fFBGDx5P5wUvGvLRHRjfC3JJGZuHylFo9/fgSnijTGbf5u9hjX1xsTB/ZEfDivhiIiag2WGyIz8MNJNf68IQvVDU3wdFTikdFhGN/PG728nSCTcV4NEVFbsNwQSahJb8BbP+Tggz0XAADRwe547/6h8HW1kzgZEZHlYrkhkkiNtgmPfXYY+85dAQA8NDIUiyb2ha1CLnEyIiLLxnJDJIGq+kYkrT6IzLxKOCoVeOOeKNwe5Sd1LCIiq8ByQ9TFymt1mPnxAZws1MDNwRafPRSHgQGuUsciIrIaLDdEXaikugEP/PMAzhTXwMtJic8ejkO/ni5SxyIisiosN0RdoFbbhIOXyvHKt6dwsawWPi4qrHlkOCK8naSORkRkdVhuiDpJjroaW0+ose9cGY7mVaBRLwA0r13zxew4BHvyZpdERJ2B5YaoE2w7qcbcNUegNwjjNn83e4zp3QNPjI9AT1d7CdMREVk3lhsiE9t3rgwLvjgKvUFgRLgnbo/yw8gITwR5OHBBPiKiLsByQ2RCR3MrMPvfh6HTGzChvy9W3D8ENly3hoioS/G3LpGJnFZr8OAnh1Cn02NUhBfemT6YxYaISAL8zUtkApfKajHz44Ooqm/EkCA3fDAzGiobhdSxiIi6JZ6WIuqgPWdKsXDdUVTWNaKvrzM+fTAWjir+1SIikgp/AxO1k8Eg8I+dZ/FO2lkIAQz0d8XHD8bA1cFW6mhERN0ayw1RO1TU6vDk+kzsOVMKALg/LgiLb4+EnS1PRRERSY3lhqiNzhRXI/mTQyiorIfKRo7X7hqIe6IDpI5FRES/YLkhaoOfz5fhsc8yUN3QhGBPB6ycEY1IP94biojInLDcELXSfzML8PSGLDTqBYaFuOPDmTFwd1RKHYuIiP4Hyw3RHxBC4P3d5/HWthwAwKSBPfF/9w3i/BoiIjPFckN0A5qGRry86RT+cyQfADB7dCgW3dYPcjlvo0BEZK5YboiuY+/ZUjzz1TEUVjVAJgMW3x6J5JGhUsciIqI/wHJD9D9qtE14/ftsfHEgFwAQ7OmAZfcOwrAQD4mTERFRa7DcEP3O2eJqJH96CPkV9QCAB0eE4K8T+sBByb8qRESWgr+xiX5xobQG9//zAEqrtQhwt8db9wxCfLin1LGIiKiNWG6IAFy+Uov7P2ouNn19nbF29nBe5k1EZKF4V3Dq9vIr6nD/Rweg1jSgl7cT1jwSx2JDRGTBWG6oWyuqqsf9Hx1AQWU9wrwcsWZ2HDydVFLHIiKiDuBpKeq2Dl0qx5PrMlFQWY9gTwd8MXs4vJ3tpI5FREQdxHJD3U6T3oB3d57DuzvPwiCAEE8HrJk9HL6uLDZERNaA5Ya6lfyKOjy5LhOHL1cAAO4e6o9X7hwAJxX/KhARWQv+Rqdu46ezZXh8TfMdvZ1VNvjbXQNw52B/qWMREZGJtWtC8a5du0ydg6hT7copwUP/OoTqhiYMCXLD9wtHs9gQEVmpdpWbCRMmIDw8HH/729+Ql5dn6kxEJrXjVDEe+3cGdE0G3BLpg/WPxiPQw0HqWERE1EnaVW4KCgowf/58fPXVVwgLC0NiYiK+/PJL6HQ6U+cj6pCtJ9R4fE0GdHoDbhvgi/dnDIXShisgEBFZs3b9lvfy8sJTTz2FzMxMHDhwAL1798bcuXPh5+eHJ554AllZWabOSdRmm48VYd4XR9CoF7g9qif+MX0IbBUsNkRE1q7Dv+mHDh2KRYsWYf78+aipqcHq1asRHR2N0aNH4+TJk6bISNRmW0+o8cS6o9AbBO4a4o/l0waz2BARdRPt/m3f2NiIr776ChMnTkRwcDC2bduGFStWoLi4GOfOnUNwcDDuvfdeU2YlapVdp0uwYO0R6A0Cdw/xx7J7B8GGxYaIqNuQCSFEW1+0YMECrF27FkIIzJw5E4888ggGDBjQYh+1Wg0/Pz8YDAaThTUFjUYDV1dXVFVVwcXFReo4ZGL7zpUh+dND0DUZMCmqJ96ZNpjFhojICrTl87td69ycOnUK7777Lu6++26oVNe+D4+XlxcvGacudfBiOR7512HjVVHLWWyIiLqldh25sWQ8cmOdMi5XIGn1QdRomzC2dw98OCsaKhuF1LGIiMhE2vL53a5/1qampmL16tVXbV+9ejXeeOONNr/fe++9h5CQENjZ2SEuLg4HDx687r5ff/01YmJi4ObmBkdHRwwePBifffZZm78nWY+07GLM+Od+1GibEB/miQ9mstgQEXVn7So3H3zwAfr27XvV9v79+2PVqlVteq/169cjJSUFS5YswZEjRzBo0CAkJiaipKTkmvt7eHjg+eefR3p6Oo4dO4bk5GQkJydj27Zt7flRyMJ9eSgPj36WgYZGA27q0wMfPxgDO1sWGyKi7qxdp6Xs7OyQnZ2N0NDQFtsvXLiAyMhINDQ0tPq94uLiMGzYMKxYsQIAYDAYEBgYiAULFuDZZ59t1XsMHToUkyZNwquvvvqH+/K0lHUQQuC9Xeew7IczAICpQwOwdOpAXu5NRGSlOv20VGBgIPbt23fV9n379sHPz6/V76PT6ZCRkYGEhITfAsnlSEhIQHp6+h++XgiBtLQ05OTkYMyYMdfcR6vVQqPRtPgiyyaEwEubThqLzdybwrHs3igWGyIiAtDOq6Vmz56NJ598Eo2NjRg3bhwAIC0tDX/961/x5z//udXvU1ZWBr1eDx8fnxbbfXx8cPr06eu+rqqqCv7+/tBqtVAoFHj//fdxyy23XHPf1NRUvPzyy63ORObv/d3n8a/0y5DJgCW3R+LBkaF//CIiIuo22lVu/vKXv+DKlSuYO3eu8X5SdnZ2eOaZZ7Bo0SKTBrwWZ2dnZGZmoqamBmlpaUhJSUFYWBhuuummq/ZdtGgRUlJSjI81Gg0CAwM7PSN1jh9OqvHWthwAwKt3DsADw4MlTkREROamXeVGJpPhjTfewIsvvojs7GzY29ujV69e113z5nq8vLygUChQXFzcYntxcTF8fX2v+zq5XI6IiAgAwODBg5GdnY3U1NRrlhuVStXmXGSectTVeGp9JgBg5vBgFhsiIrqmDk1ScHJywrBhwzBgwIB2FQilUono6GikpaUZtxkMBqSlpSE+Pr7V72MwGKDVatv8/clyVNTq8Mi/D6FWp0d8mCcWT46UOhIREZmpdh25AYDDhw/jyy+/RG5urvHU1K++/vrrVr9PSkoKkpKSEBMTg9jYWCxfvhy1tbVITk4GAMyaNQv+/v5ITU0F0DyHJiYmBuHh4dBqtfj+++/x2WefYeXKle39UcjMNeoNmLvmCPLK6xHoYY/3Zwzl5GEiIrqudpWbdevWYdasWUhMTMQPP/yAW2+9FWfOnEFxcTHuuuuuNr3XtGnTUFpaisWLF0OtVmPw4MHYunWrcZJxbm4u5PLfPshqa2sxd+5c5Ofnw97eHn379sXnn3+OadOmtedHITPXpDfgmf8cQ/qFK3BUKvDPWcPg7qiUOhYREZmxdq1zExUVhcceewzz5s2Ds7MzsrKyEBoaisceeww9e/Y066uTuM6N5dA26bFwbSa2nlRDIZdh1QPRuCXS549fSEREVqfT17k5f/48Jk2aBKB53kxtbS1kMhmeeuopfPjhh+15S6IW6nRNeORfh7H1pBpKhRzvzxjKYkNERK3SrnLj7u6O6upqAIC/vz9OnDgBAKisrERdXZ3p0lG3VFXXiAf+eQB7z5bBQanA6geHIbH/9a+eIyIi+r12zbkZM2YMtm/fjoEDB+Lee+/FwoULsXPnTmzfvh3jx483dUbqRipqdbj/nweQXaSBq70tPkkehqFB7lLHIiIiC9KucrNixQrj/aOef/552Nra4ueff8bUqVPxwgsvmDQgdR/1Oj0e/tchZBdp0MNZhc8ejkVfX86LIiKitmlzuWlqasJ3332HxMREAM0L6rX2BpdE19OkN2DB2qM4klsJV3tbfPFIHHr5OEsdi4iILFCb59zY2Nhgzpw5bbrzN9GNCCHw4n9PYEd2MVQ2cvwzKYbFhoiI2q1dE4pjY2ORmZlp4ijUXS3fcRZrD+ZBLgP+MX0IhoV4SB2JiIgsWLvm3MydOxcpKSnIy8tDdHQ0HB0dWzwfFRVlknBk/dYfysU7aWcBAK/cOYBXRRERUYe1axG/368YbHwjmQxCCMhkMuj1epOE6wxcxM98XL5Si8TlP6Kh0YAF4yLw51v7SB2JiIjMVFs+v9t15ObixYvtCkb0KyEEnv3PcTQ0GhAf5omUW3pLHYmIiKxEu8pNcHCwqXNQN7P+UB7SL1yBna0cS6cOhEwmkzoSERFZiXaVm3//+983fH7WrFntCkPdg7qqAa9tzgYAPH1rHwR7Ov7BK4iIiFqvXeVm4cKFLR43Njairq4OSqUSDg4OLDd0XUIIvLDxOKq1TRgU6IbkkaFSRyIiIivTrkvBKyoqWnzV1NQgJycHo0aNwtq1a02dkazId8eKsCO7BLYKGd6cGgWFnKejiIjItNpVbq6lV69eWLp06VVHdYh+VV6rw0ubTgIA5t0cgT6+XKiPiIhMz2TlBmhevbiwsNCUb0lWQgiBv2zIwpVaHXr7OGHuTRFSRyIiIivVrjk3mzZtavFYCIGioiKsWLECI0eONEkwsi6r911C2ukSKG3k+Pu0wVDamLRXExERGbWr3EyZMqXFY5lMhh49emDcuHH4v//7P1PkIityLL8SS7c0Xx31wqR+6O/nKnEiIiKyZu0qNwaDwdQ5yEpVNzRiwdqjaNQLJPb3wczhXCOJiIg6F88NUKcRQuD5b07g8pU6+LvZ482pg7hYHxERdbp2lZupU6fijTfeuGr7m2++iXvvvbfDocg6bDicj01ZhVDIZfjH9MFwdbCVOhIREXUD7So3P/74IyZOnHjV9ttuuw0//vhjh0OR5SvWNODlb5sv+/7zrb0RHewhcSIiIuou2lVuampqoFQqr9pua2sLjUbT4VBk+V7bnI1anR5DgtwwZ0y41HGIiKgbaVe5GThwINavX3/V9nXr1iEyMrLDociy/Xy+DJuyCiGTAa/eOQByrkJMRERdqF1XS7344ou4++67cf78eYwbNw4AkJaWhrVr12LDhg0mDUiWpVFvwJL/Np+OeiAuGAP8edk3ERF1rXaVm8mTJ2Pjxo14/fXX8dVXX8He3h5RUVHYsWMHxo4da+qMZEE+3XcJZ0tq4OGoxNO39pE6DhERdUPtKjcAMGnSJEyaNMmUWcjCqasasHzHGQDAsxP68uooIiKSRLvm3Bw6dAgHDhy4avuBAwdw+PDhDociy/Ta979NIr4nOkDqOERE1E21q9zMmzcPeXl5V20vKCjAvHnzOhyKLM+eM6X4NqsQck4iJiIiibWr3Jw6dQpDhw69avuQIUNw6tSpDociy5JXXoeF644CAGYO5yRiIiKSVrvKjUqlQnFx8VXbi4qKYGPT7mk8ZIHqdE2Y/e/DqKxrxKAAVyya2E/qSERE1M21q9zceuutWLRoEaqqqozbKisr8dxzz+GWW24xWTgyb0II/GXDMZxWV8PLSYVVM6NhZ6uQOhYREXVz7TrMsmzZMowZMwbBwcEYMmQIACAzMxM+Pj747LPPTBqQzNf7u89j8/Ei2CpkWPXAUPR0tZc6EhERUfvKjb+/P44dO4Y1a9YgKysL9vb2SE5OxvTp02Fry8t/u4Ndp0uw7IccAMDLdwxATAjvHUVEROah3RNkHB0dMWrUKAQFBUGn0wEAtmzZAgC44447TJOOzFJptRYL1x2FEMD9cUG4Py5I6khERERG7So3Fy5cwF133YXjx49DJpNBCAGZ7LdLf/V6vckCkvlJ/T4bmoYm9PdzwUuT+0sdh4iIqIV2TSheuHAhQkNDUVJSAgcHB5w4cQJ79uxBTEwMdu/ebeKIZE7Sz1/B10cLIJMBr981EEqbdv0vRERE1GnadeQmPT0dO3fuhJeXF+RyORQKBUaNGoXU1FQ88cQTOHr0qKlzkhnQNRnw4n9PAABmxAVhUKCbtIGIiIiuoV3/7Nbr9XB2dgYAeHl5obCwEAAQHByMnJwc06Ujs/LPny7gXEkNvJyU+MutfaWOQ0REdE3tOnIzYMAAZGVlITQ0FHFxcXjzzTehVCrx4YcfIiwszNQZyQzkV9ThH2lnAQDPTezHm2ISEZHZale5eeGFF1BbWwsAeOWVV3D77bdj9OjR8PT0xPr1600akMzDS5tOoaHRgNhQD9w1xF/qOERERNfVrnKTmJho/HNERAROnz6N8vJyuLu7t7hqiqzDjlPF2JFdDBu5DH+bMoD/jYmIyKyZ7EZQHh5cxM0aaZv0eHVz881QHx4dit4+zhInIiIiujFex0s39Om+S7h8pQ49nFVYMK6X1HGIiIj+EMsNXVdptRbv7jwHAPhrYh84qXjHdyIiMn8sN3Rdb2/PQY22CQP9XTF1aIDUcYiIiFqF5Yau6WRhFdYdygMALJ4cCbmck4iJiMgysNzQVYQQeOXbUxACuD2qJ4bxjt9ERGRBWG7oKltPqHHgYjlUNnIsmthP6jhERERtwnJDLTQ06vH6lmwAwGNjwuDvZi9xIiIiorZhuaEW3t15Fnnl9fB1scOcm8KljkNERNRmLDdklKOuxgd7LgAAXrqjPxyUvPSbiIgsD8sNAQAMBoHnvjmOJoPALZE+mDDAV+pIRERE7cJyQwCALw7mIuNyBRyVCrx8R3+p4xAREbUbyw2hRNOAN7aeBgA8ndgHfpxETEREFozlhvDyt6dQ3dCEQQGumBUfInUcIiKiDmG56eZ2ni7G5uNFUMhleP3ugVBwJWIiIrJwLDfdmBACb2zJAQA8PCoU/f1cJU5ERETUcSw33diunBLkFFfDSWWDeTdHSB2HiIjIJFhuurFVu5vXtLk/Lgiu9rYSpyEiIjINlptuKuNyOQ5eKodSIcfDo0KljkNERGQyLDfd1MpfjtrcPdQfPi52EqchIiIyHbMoN++99x5CQkJgZ2eHuLg4HDx48Lr7fvTRRxg9ejTc3d3h7u6OhISEG+5PVztTXI0d2cWQyYBHx4RJHYeIiMikJC8369evR0pKCpYsWYIjR45g0KBBSExMRElJyTX33717N6ZPn45du3YhPT0dgYGBuPXWW1FQUNDFyS3Xqj3nAQAT+vsirIeTxGmIiIhMSyaEEFIGiIuLw7Bhw7BixQoAgMFgQGBgIBYsWIBnn332D1+v1+vh7u6OFStWYNasWVc9r9VqodVqjY81Gg0CAwNRVVUFFxcX0/0gFqKgsh5j39yFJoPAf+eNxKBAN6kjERER/SGNRgNXV9dWfX5LeuRGp9MhIyMDCQkJxm1yuRwJCQlIT09v1XvU1dWhsbERHh4e13w+NTUVrq6uxq/AwECTZLdU/9x7AU0GgRHhniw2RERklSQtN2VlZdDr9fDx8Wmx3cfHB2q1ulXv8cwzz8DPz69FQfq9RYsWoaqqyviVl5fX4dyWqqJWh3UHm3/+OWPDJU5DRETUOWykDtARS5cuxbp167B7927Y2V37ih+VSgWVStXFyczTFwdzUd+oR2RPF4zu5SV1HCIiok4habnx8vKCQqFAcXFxi+3FxcXw9fW94WuXLVuGpUuXYseOHYiKiurMmFZB12TAv36+BACYPSYUMhnvIUVERNZJ0tNSSqUS0dHRSEtLM24zGAxIS0tDfHz8dV/35ptv4tVXX8XWrVsRExPTFVEt3nfHClFSrYWPiwqTBvpJHYeIiKjTSH5aKiUlBUlJSYiJiUFsbCyWL1+O2tpaJCcnAwBmzZoFf39/pKamAgDeeOMNLF68GF988QVCQkKMc3OcnJzg5MTLmq9FCIF/7r0IAEgaEQKljeQrABAREXUaycvNtGnTUFpaisWLF0OtVmPw4MHYunWrcZJxbm4u5PLfPoxXrlwJnU6He+65p8X7LFmyBC+99FJXRrcY6Reu4FSRBva2CtwfGyR1HCIiok4l+To3Xa0t18lbi0f+dQg7skswc3gwXp0yQOo4REREbWYx69xQ57tQWoMd2SWQyYDkkSFSxyEiIup0LDdWbvW+5rk24/t681YLRETULbDcWLHKOh2+ysgHADw8ijfIJCKi7oHlxoqtOZCLhkYD+vu5YHjYtW9PQUREZG1YbqxUQ6Men+y7BAB4eBQX7SMiou6D5cZKrT2Yi7IaLQLc7TF5EBftIyKi7oPlxgo1NOqxas95AMDcmyJgq+B/ZiIi6j74qWeFNhzOQ7FGi56udpga7S91HCIioi7FcmNldE0GrNzdfNTm8ZvCobJRSJyIiIioa7HcWJn/HMlHYVUDvJ1VuC8mUOo4REREXY7lxoo06g14f/c5AMBjY8NhZ8ujNkRE1P2w3FiRjUcLkFdeDy8nJW+QSURE3RbLjZVo0hvw/i9zbR4ZHQZ7JY/aEBFR98RyYyW2nFDjYlkt3B1sMXN4sNRxiIiIJMNyYyU+/fkSAGBmfAgcVTbShiEiIpIQy40VOJ5fhYzLFbBVyPBAHOfaEBFR98ZyYwV+PWozcWBPeLvYSRuGiIhIYiw3Fq6sRotvswoBAA+OCJE2DBERkRlgubFwaw/kQqc3YFCgG4YEuUsdh4iISHIsNxasUW/A5wcuAwCSedSGiIgIAMuNRdt6Qo1ijRZeTipMHNhT6jhERERmgeXGgv06kXhGXBCUNvxPSUREBLDcWKxj+ZXGy79n8PJvIiIiI5YbC8XLv4mIiK6N5cYC1WqbsPlYEQAgiROJiYiIWmC5sUA7souhbTIgxNMBQwLdpI5DRERkVlhuLNB3vxy1mRTVEzKZTOI0RERE5oXlxsJoGhqxJ6cUAHB7lJ/EaYiIiMwPy42F2X6yGDq9AeE9HNHX11nqOERERGaH5cbCbD7efErq9ig/npIiIiK6BpYbC1JV14i9Z389JcUViYmIiK6F5caCbDupRqNeoI+PM3r58JQUERHRtbDcWJBvjxUC4FEbIiKiG2G5sRDltTr8fP4KAOD2QbxKioiI6HpYbizE1hNq6A0C/f1cEOrlKHUcIiIis8VyYyG+M56S4lEbIiKiG2G5sQCl1Vrsv9B8SmrSQM63ISIiuhGWGwuw5UQRDAIYFOCKIE8HqeMQERGZNZYbC/BtVvMpqcmcSExERPSHWG7MXEFlPQ5dqoBMxvk2RERErcFyY+a+++WozbAQD/i62kmchoiIyPyx3Ji5Tb+Umzt4SoqIiKhVWG7M2PnSGpws1MBGLsNEXiVFRETUKiw3ZuzXicSjennBw1EpcRoiIiLLwHJjpoQQxlNSkzmRmIiIqNVYbszUqSINLpTWQmUjx639faSOQ0REZDFYbszUr0dtxvX1hrOdrcRpiIiILAfLjRkyGAS+yyoCwKukiIiI2orlxgwdzatAQWU9nFQ2uLmvt9RxiIiILArLjRnalNl8SurWSB/Y2SokTkNERGRZWG7MjMEgsPm4GgAweTBPSREREbUVy42ZyVZrUFajhaNSgVERXlLHISIisjgsN2Ym/fwVAEBsqAdsFfzPQ0RE1Fb89DQzv5ab+HBPiZMQERFZJpYbM9KkN+DgxXIAQHwYT0kRERG1B8uNGTlRqEG1tgkudjaI9HOROg4REZFFYrkxI7+ekooL84RCLpM4DRERkWViuTEj6Reay80IzrchIiJqN5YbM6FrMuDQr/NtWG6IiIjajeXGTBzLr0R9ox6ejkr09naWOg4REZHFYrkxEz//Mt9meJgn5JxvQ0RE1G6Sl5v33nsPISEhsLOzQ1xcHA4ePHjdfU+ePImpU6ciJCQEMpkMy5cv77qgnezXycTDeUqKiIioQyQtN+vXr0dKSgqWLFmCI0eOYNCgQUhMTERJSck196+rq0NYWBiWLl0KX1/fLk7beRoa9cjIrQDAycREREQdJWm5efvttzF79mwkJycjMjISq1atgoODA1avXn3N/YcNG4a33noLf/rTn6BSqbo4bec5klsBXZMB3s4qhHk5Sh2HiIjIoklWbnQ6HTIyMpCQkPBbGLkcCQkJSE9PN9n30Wq10Gg0Lb7Mza+npEaEe0Im43wbIiKijpCs3JSVlUGv18PHx6fFdh8fH6jVapN9n9TUVLi6uhq/AgMDTfbepsL7SREREZmO5BOKO9uiRYtQVVVl/MrLy5M6Ugt1uiZk5lUCAEaE835SREREHWUj1Tf28vKCQqFAcXFxi+3FxcUmnSysUqnMen7OoUsVaDII+LvZI9DDQeo4REREFk+yIzdKpRLR0dFIS0szbjMYDEhLS0N8fLxUsbocT0kRERGZlmRHbgAgJSUFSUlJiImJQWxsLJYvX47a2lokJycDAGbNmgV/f3+kpqYCaJ6EfOrUKeOfCwoKkJmZCScnJ0REREj2c3TE/l/uJxUfxnJDRERkCpKWm2nTpqG0tBSLFy+GWq3G4MGDsXXrVuMk49zcXMjlvx1cKiwsxJAhQ4yPly1bhmXLlmHs2LHYvXt3V8fvsFptE44XVAEA4sI8JE5DRERkHWRCCCF1iK6k0Wjg6uqKqqoquLi4SJrlxzOlmLX6IPzd7LHv2XGSZiEiIjJnbfn8tvqrpczZgYvNp6R41IaIiMh0WG4kdOBCOQBgeCjn2xAREZkKy41E6nV6ZOVXAmi+EzgRERGZBsuNRI7kVqBRL9DT1Q6BHvZSxyEiIrIaLDcSOfDLJeBxoR68nxQREZEJsdxIZP/F5vk2cTwlRUREZFIsNxJoaNQjM7cSAOfbEBERmRrLjQSO5lZCpzfA21mFEE/eT4qIiMiUWG4k8Nv6Np6cb0NERGRiLDcS+HV9m7hQLt5HRERkaiw3XUzbpMeR3AoAwHCuTExERGRyLDddLCuvCtomA7yclAjv4SR1HCIiIqvDctPFflvfhvNtiIiIOgPLTRc7YFzfhqekiIiIOgPLTRfSNRmQcbl5vk0cb5ZJRETUKVhuutD+C1dQ36iHl5MSvbw534aIiKgzsNx0oS0nigAAif19IZdzvg0REVFnYLnpIk16A7adLAYATBzYU+I0RERE1ovlposcvFiO8lod3B1suXgfERFRJ2K56SLf/+6UlI2Cw05ERNRZ+CnbBfQGga0nmk9J3cZTUkRERJ2K5aYLHLpUjrIaLVztbTEinJeAExERdSaWmy6w5XjzKalbIn1gy1NSREREnYqftJ3MYBDYckINAJg40FfiNERERNaP5aaTHcmtQEm1Fs4qG4yM8JI6DhERkdVjuelk3x9vPmpzS6QPVDYKidMQERFZP5abTtR8Sqp5vg2vkiIiIuoaLDedKCu/EkVVDXBUKjC6F09JERERdQWWm05SVqPF33ecBQCM7+cDO1uekiIiIuoKNlIHsDZCCHyVkY/Xvs9GZV0j5DJgRlyQ1LGIiIi6DZYbE7pYVovnvj6O9AtXAACRPV2wdOpARAW4SRuMiIioG2G5MZGtJ9R4Yt1R6JoMsLOV46mE3nhoVCgX7SMiIupiLDcmMjjQDUqFHHGhHnhtykAEeTpIHYmIiKhbYrkxEV9XO3y7YBRCPB0gk8mkjkNERNRtsdyYUKiXo9QRiIiIuj1OCCEiIiKrwnJDREREVoXlhoiIiKwKyw0RERFZFZYbIiIisiosN0RERGRVWG6IiIjIqrDcEBERkVVhuSEiIiKrwnJDREREVoXlhoiIiKwKyw0RERFZFZYbIiIisird7q7gQggAgEajkTgJERERtdavn9u/fo7fSLcrN9XV1QCAwMBAiZMQERFRW1VXV8PV1fWG+8hEayqQFTEYDCgsLISzszNkMplJ31uj0SAwMBB5eXlwcXEx6XtTSxzrrsOx7joc667Dse46phprIQSqq6vh5+cHufzGs2q63ZEbuVyOgICATv0eLi4u/MvSRTjWXYdj3XU41l2HY911TDHWf3TE5lecUExERERWheWGiIiIrArLjQmpVCosWbIEKpVK6ihWj2PddTjWXYdj3XU41l1HirHudhOKiYiIyLrxyA0RERFZFZYbIiIisiosN0RERGRVWG6IiIjIqrDcmMh7772HkJAQ2NnZIS4uDgcPHpQ6ksVLTU3FsGHD4OzsDG9vb0yZMgU5OTkt9mloaMC8efPg6ekJJycnTJ06FcXFxRIlth5Lly6FTCbDk08+adzGsTadgoICPPDAA/D09IS9vT0GDhyIw4cPG58XQmDx4sXo2bMn7O3tkZCQgLNnz0qY2DLp9Xq8+OKLCA0Nhb29PcLDw/Hqq6+2uDcRx7r9fvzxR0yePBl+fn6QyWTYuHFji+dbM7bl5eWYMWMGXFxc4Obmhocffhg1NTUdDyeow9atWyeUSqVYvXq1OHnypJg9e7Zwc3MTxcXFUkezaImJieKTTz4RJ06cEJmZmWLixIkiKChI1NTUGPeZM2eOCAwMFGlpaeLw4cNi+PDhYsSIERKmtnwHDx4UISEhIioqSixcuNC4nWNtGuXl5SI4OFg8+OCD4sCBA+LChQti27Zt4ty5c8Z9li5dKlxdXcXGjRtFVlaWuOOOO0RoaKior6+XMLnlee2114Snp6f47rvvxMWLF8WGDRuEk5OTeOedd4z7cKzb7/vvvxfPP/+8+PrrrwUA8c0337R4vjVjO2HCBDFo0CCxf/9+sXfvXhERESGmT5/e4WwsNyYQGxsr5s2bZ3ys1+uFn5+fSE1NlTCV9SkpKREAxJ49e4QQQlRWVgpbW1uxYcMG4z7Z2dkCgEhPT5cqpkWrrq4WvXr1Etu3bxdjx441lhuOtek888wzYtSoUdd93mAwCF9fX/HWW28Zt1VWVgqVSiXWrl3bFRGtxqRJk8RDDz3UYtvdd98tZsyYIYTgWJvS/5ab1oztqVOnBABx6NAh4z5btmwRMplMFBQUdCgPT0t1kE6nQ0ZGBhISEozb5HI5EhISkJ6eLmEy61NVVQUA8PDwAABkZGSgsbGxxdj37dsXQUFBHPt2mjdvHiZNmtRiTAGOtSlt2rQJMTExuPfee+Ht7Y0hQ4bgo48+Mj5/8eJFqNXqFmPt6uqKuLg4jnUbjRgxAmlpaThz5gwAICsrCz/99BNuu+02ABzrztSasU1PT4ebmxtiYmKM+yQkJEAul+PAgQMd+v7d7saZplZWVga9Xg8fH58W2318fHD69GmJUlkfg8GAJ598EiNHjsSAAQMAAGq1GkqlEm5ubi329fHxgVqtliClZVu3bh2OHDmCQ4cOXfUcx9p0Lly4gJUrVyIlJQXPPfccDh06hCeeeAJKpRJJSUnG8bzW7xSOdds8++yz0Gg06Nu3LxQKBfR6PV577TXMmDEDADjWnag1Y6tWq+Ht7d3ieRsbG3h4eHR4/FluyCLMmzcPJ06cwE8//SR1FKuUl5eHhQsXYvv27bCzs5M6jlUzGAyIiYnB66+/DgAYMmQITpw4gVWrViEpKUnidNblyy+/xJo1a/DFF1+gf//+yMzMxJNPPgk/Pz+OtZXjaakO8vLygkKhuOqqkeLiYvj6+kqUyrrMnz8f3333HXbt2oWAgADjdl9fX+h0OlRWVrbYn2PfdhkZGSgpKcHQoUNhY2MDGxsb7NmzB//4xz9gY2MDHx8fjrWJ9OzZE5GRkS229evXD7m5uQBgHE/+Tum4v/zlL3j22Wfxpz/9CQMHDsTMmTPx1FNPITU1FQDHujO1Zmx9fX1RUlLS4vmmpiaUl5d3ePxZbjpIqVQiOjoaaWlpxm0GgwFpaWmIj4+XMJnlE0Jg/vz5+Oabb7Bz506Ehoa2eD46Ohq2trYtxj4nJwe5ubkc+zYaP348jh8/jszMTONXTEwMZsyYYfwzx9o0Ro4cedWSBmfOnEFwcDAAIDQ0FL6+vi3GWqPR4MCBAxzrNqqrq4Nc3vJjTqFQwGAwAOBYd6bWjG18fDwqKyuRkZFh3Gfnzp0wGAyIi4vrWIAOTUcmIUTzpeAqlUp8+umn4tSpU+LRRx8Vbm5uQq1WSx3Noj3++OPC1dVV7N69WxQVFRm/6urqjPvMmTNHBAUFiZ07d4rDhw+L+Ph4ER8fL2Fq6/H7q6WE4FibysGDB4WNjY147bXXxNmzZ8WaNWuEg4OD+Pzzz437LF26VLi5uYn//ve/4tixY+LOO+/k5cntkJSUJPz9/Y2Xgn/99dfCy8tL/PWvfzXuw7Fuv+rqanH06FFx9OhRAUC8/fbb4ujRo+Ly5ctCiNaN7YQJE8SQIUPEgQMHxE8//SR69erFS8HNybvvviuCgoKEUqkUsbGxYv/+/VJHsngArvn1ySefGPepr68Xc+fOFe7u7sLBwUHcddddoqioSLrQVuR/yw3H2nS+/fZbMWDAAKFSqUTfvn3Fhx9+2OJ5g8EgXnzxReHj4yNUKpUYP368yMnJkSit5dJoNGLhwoUiKChI2NnZibCwMPH8888LrVZr3Idj3X67du265u/opKQkIUTrxvbKlSti+vTpwsnJSbi4uIjk5GRRXV3d4WwyIX63VCMRERGRheOcGyIiIrIqLDdERERkVVhuiIiIyKqw3BAREZFVYbkhIiIiq8JyQ0RERFaF5YaIiIisCssNERERWRWWGyLqlmQyGTZu3Ch1DCLqBCw3RNTlHnzwQchksqu+JkyYIHU0IrICNlIHIKLuacKECfjkk09abFOpVBKlISJrwiM3RCQJlUoFX1/fFl/u7u4Amk8ZrVy5Erfddhvs7e0RFhaGr776qsXrjx8/jnHjxsHe3h6enp549NFHUVNT02Kf1atXo3///lCpVOjZsyfmz5/f4vmysjLcddddcHBwQK9evbBp0ybjcxUVFZgxYwZ69OgBe3t79OrV66oyRkTmieWGiMzSiy++iKlTpyIrKwszZszAn/70J2RnZwMAamtrkZiYCHd3dxw6dAgbNmzAjh07WpSXlStXYt68eXj00Udx/PhxbNq0CRERES2+x8svv4z77rsPx44dw8SJEzFjxgyUl5cbv/+pU6ewZcsWZGdnY+XKlfDy8uq6ASCi9uvwfcWJiNooKSlJKBQK4ejo2OLrtddeE0IIAUDMmTOnxWvi4uLE448/LoQQ4sMPPxTu7u6ipqbG+PzmzZuFXC4XarVaCCGEn5+feP7556+bAYB44YUXjI9ramoEALFlyxYhhBCTJ08WycnJpvmBiahLcc4NEUni5ptvxsqVK1ts8/DwMP45Pj6+xXPx8fHIzMwEAGRnZ2PQoEFwdHQ0Pj9y5EgYDAbk5ORAJpOhsLAQ48ePv2GGqKgo458dHR3h4uKCkpISAMDjjz+OqVOn4siRI7j11lsxZcoUjBgxol0/KxF1LZYbIpKEo6PjVaeJTMXe3r5V+9na2rZ4LJPJYDAYAAC33XYbLl++jO+//x7bt2/H+PHjMW/ePCxbtszkeYnItDjnhojM0v79+6963K9fPwBAv379kJWVhdraWuPz+/btg1wuR58+feDs7IyQkBCkpaV1KEOPHj2QlJSEzz//HMuXL8eHH37Yofcjoq7BIzdEJAmtVgu1Wt1im42NjXHS7oYNGxATE4NRo0ZhzZo1OHjwID7++GMAwIwZM7BkyRIkJSXhpZdeQmlpKRYsWICZM2fCx8cHAPDSSy9hzpw58Pb2xm233Ybq6mrs27cPCxYsaFW+xYsXIzo6Gv3794dWq8V3331nLFdEZN5YbohIElu3bkXPnj1bbOvTpw9Onz4NoPlKpnXr1mHu3Lno2bMn1q5di8jISACAg4MDtm3bhoULF2LYsGFwcHDA1KlT8fbbbxvfKykpCQ0NDfj73/+Op59+Gl5eXrjnnntanU+pVGLRokW4dOkS7O3tMXr0aKxbt84EPzkRdTaZEEJIHYKI6PdkMhm++eYbTJkyReooRGSBOOeGiIiIrArLDREREVkVzrkhIrPDs+VE1BE8ckNERERWheWGiIiIrArLDREREVkVlhsiIiKyKiw3REREZFVYboiIiMiqsNwQERGRVWG5ISIiIqvy/0Nxu5HbCWVkAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P96oVMk3lU7y",
        "outputId": "43484a6e-176f-4ae8-89d9-c261bfb73b50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 627ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "im feeling chills me in the sky and thinks his love song real a rain cloud in my eyes help havent happy song of place more comin comin more a and turn on a cobweb of me small meant or cinderella happy hawaii wide missin birds knowsyeah hard is a ride and nancy close youre ahha ahha ahha ahha ahha closed a knees mia forever song be it a longer yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "outputId": "63995575-1462-4e2c-e15f-699352a33fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "outputId": "0904f489-699f-42f0-f3ca-319b27330d22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "im feeling chills me in out but your kiss would hear you become speed married explode down and yeah dance together through away what couldnt kiss rhyme reflections of everybody mama jet haria power ocean realize cars learn fiddle shove you play it with your heal teach cries coat for thats candle escape parted within hold fever everywhere piece ho write sorrow lala laah still on the crowd worries im gonna to believe it now ya if i knew the devil you care the neon for the final song same familiar shoes on faces small or short right like everything doing her fucks\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}